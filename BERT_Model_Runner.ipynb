{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import functools\n",
    "import operator\n",
    "#import boto3, re, sys, math, json, sagemaker\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, RobertaForSequenceClassification, RobertaTokenizer, DistilBertForSequenceClassification, DistilBertTokenizer, AlbertForSequenceClassification, AlbertTokenizer, get_linear_schedule_with_warmup\n",
    "from transformers import BartForSequenceClassification, BartTokenizer, XLNetForSequenceClassification, XLNetTokenizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm, trange\n",
    "#from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify(data, strata_field: str, split_sizes, **kwargs):\n",
    "    \"\"\"Stratify and split the data.\n",
    "    :data (base.DataType): dataset to split.\n",
    "    :split_sizes (int | base.List[int]): The number of documents in each split.\n",
    "    :strata_field (str): Name of label field.\n",
    "    :returns train, dev, test (base.Tuple[list, base.Union[list, None], list]): Return stratified splits.\n",
    "    \"\"\"\n",
    "\n",
    "    train_size = split_sizes[0]\n",
    "\n",
    "    num_splits = len(split_sizes)\n",
    "    if num_splits == 1:\n",
    "        test_size = 1 - split_sizes[0]\n",
    "    elif num_splits == 2:\n",
    "        test_size = split_sizes[-1]\n",
    "    elif num_splits == 3:\n",
    "        dev_size = split_sizes[1]\n",
    "        test_size = split_sizes[2]\n",
    "\n",
    "    stratified_train_list = []\n",
    "    stratified_dev_list = []\n",
    "    stratified_test_list = []\n",
    "\n",
    "    for i in set(data[strata_field]):\n",
    "        temp_df = data[data[strata_field] == i]\n",
    "\n",
    "        if dev_size is not None:\n",
    "            train, temp_test = train_test_split(temp_df, test_size=test_size+dev_size, random_state=42)\n",
    "            dev, test = train_test_split(temp_test, test_size= (test_size/(test_size+dev_size)), random_state=42)\n",
    "\n",
    "            stratified_train_list.append(train)\n",
    "            stratified_dev_list.append(dev)\n",
    "            stratified_test_list.append(test)\n",
    "\n",
    "        else:\n",
    "            train, test = train_test_split()\n",
    "            stratified_train_list.append(train)\n",
    "            stratified_test_list.append(test)\n",
    "\n",
    "\n",
    "    train = pd.concat(stratified_train_list)\n",
    "    dev = pd.concat(stratified_dev_list)\n",
    "    test = pd.concat(stratified_test_list)\n",
    "\n",
    "    train = shuffle(train).reset_index(drop=True)\n",
    "    dev = shuffle(dev).reset_index(drop=True)\n",
    "    test = shuffle(test).reset_index(drop=True)\n",
    "\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = stratify(df, \"\", [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#role = get_execution_role()\n",
    "#train = pd.read_csv(\"s3://eastasianprejudice/Data/east_asian_prejudice_train.csv\", encoding='utf-8')\n",
    "#dev = pd.read_csv(\"s3://eastasianprejudice/Data/east_asian_prejudice_dev.csv\", encoding='utf-8')\n",
    "#test = pd.read_csv(\"s3://eastasianprejudice/Data/east_asian_prejudice_test.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, model, num_labels: int):\n",
    "        \"\"\"\n",
    "        model: From HuggingFace transformers library\n",
    "\n",
    "        num_labels (int): Number of annotation classes\n",
    "        \"\"\"\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.model_types = {\"BERT\": [BertForSequenceClassification, BertTokenizer, 'bert-large-uncased'], #'bert-base-uncased'\n",
    "          \"RoBERTa\": [RobertaForSequenceClassification, RobertaTokenizer, 'roberta-large'], #'roberta-base'\n",
    "          \"DistilBERT\": [DistilBertForSequenceClassification, DistilBertTokenizer, 'distilbert-base-cased'], \n",
    "          \"AlBERT\": [AlbertForSequenceClassification, AlbertTokenizer, 'albert-xlarge-v2'],  # 'albert-xlarge-v2' \"albert-large-v2\" 'albert-base-v2' 'albert-xxlarge-v2'\n",
    "          \"BART\": [BartForSequenceClassification, BartTokenizer, \"bart-large\"],  \n",
    "          \"XLNet\": [XLNetForSequenceClassification, XLNetTokenizer, \"xlnet-large-cased\"], #\"xlnet-base-cased\"\n",
    "          } \n",
    "        self.model_selection = model\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model_types[self.model_selection][0].from_pretrained(self.model_types[self.model_selection][2], num_labels = num_labels).to(self.device)\n",
    "        self.seed_val = 22\n",
    "\n",
    "        random.seed(self.seed_val)\n",
    "        np.random.seed(self.seed_val)\n",
    "        torch.manual_seed(self.seed_val)\n",
    "        if self.device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(self.seed_val)\n",
    "\n",
    "    def clean(self, data, normalize_list, annotate_list, labels):\n",
    "        \"\"\"\n",
    "        This function preprocesses the text using the Ekphrasis library\n",
    "        \n",
    "        data: Pandas series object containing strings of text\n",
    "\n",
    "        normalize_list: list of data features to clean\n",
    "\n",
    "        annotate_list: list of data features to annotate\n",
    "\n",
    "        labels: Pandas series containing data annotations\n",
    "        \"\"\"\n",
    "\n",
    "        text_processor = TextPreProcessor(\n",
    "            normalize= normalize_list,\n",
    "            annotate= annotate_list,\n",
    "            fix_html=True,\n",
    "            segmenter=\"twitter\", \n",
    "            #unpack_hashtags=False,  \n",
    "            #unpack_contractions=False,  \n",
    "            #spell_correct_elong=False,  \n",
    "            tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "            dicts=[emoticons]\n",
    "        )\n",
    "\n",
    "        clean_data = data.map(lambda x: \" \".join(text_processor.pre_process_doc(x)))\n",
    "\n",
    "        return self.preprocesser(clean_data, labels)\n",
    "\n",
    "  \n",
    "    def preprocesser(self, sequence, labels):\n",
    "        \"\"\"\n",
    "        This function converts a string of text into a tokenized format compatible with the selected model\n",
    "\n",
    "        sequence: An iterable series of data (i.e. Pandas Series, list..) where elements are strings\n",
    "\n",
    "        labels: Pandas series containing data annotations\n",
    "        \"\"\"\n",
    "\n",
    "        self.tokenizer = self.model_types[self.model_selection][1].from_pretrained(self.model_types[self.model_selection][2])\n",
    "\n",
    "        indexed_tokens = []\n",
    "        attention_masks = []\n",
    "\n",
    "\n",
    "        for counter, sentence in enumerate(sequence):\n",
    "            if counter % 1000 == 0:\n",
    "                print(\"Processing row {}\".format(counter))\n",
    "            if counter == len(sequence):\n",
    "                print(\"Done!\")\n",
    "\n",
    "\n",
    "            encoded_dict = self.tokenizer.encode_plus(\n",
    "                      sentence,            \n",
    "                      add_special_tokens = True,\n",
    "                      max_length = self.pad_length,         \n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,  \n",
    "                      return_tensors = 'pt',   \n",
    "                  )\n",
    "  \n",
    "            indexed_tokens.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        return self.batcher(torch.cat(indexed_tokens, dim=0), torch.cat(attention_masks, dim=0), labels)\n",
    "\n",
    "\n",
    "    def batcher(self, indexed_tokens, attention_masks, labels):\n",
    "        \"\"\"\n",
    "        This function creates batches of a specified size to save on memory\n",
    "\n",
    "        indexed_tokens: Tokenized text output by model preprocesser\n",
    "\n",
    "        attention_masks: Attention masks output by model preprocesser\n",
    "\n",
    "        labels: Pandas series containing data annotations\n",
    "        \"\"\"\n",
    "\n",
    "        data = TensorDataset(indexed_tokens, attention_masks, labels)\n",
    "        sampler = SequentialSampler(data)\n",
    "        dataloader = DataLoader(data, sampler=sampler, batch_size = self.batch_size)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "\n",
    "    def fine_tune(self, train_data, train_labels, dev_data, dev_labels, normalize_list, annotate_list, pad_length: int, early_stop_vals: dict, batch_size: int = 32, epochs: int = 3, learning_rate: float = 2e-5, weight_decay: float = 0.1, warmup: float = 0.06):   \n",
    "        \"\"\"\n",
    "        Updates pre-trained model's weights based on given dataset\n",
    "\n",
    "        train_data: Pandas series object containing text data for train set\n",
    "\n",
    "        train_labels: Pandas series object containing ground truth annotations for train set\n",
    "\n",
    "        dev_data: Pandas series object containing text data for dev set\n",
    "\n",
    "        dev_labels: Pandas series object containing ground truth annotations for dev set\n",
    "\n",
    "        normalize_list: list of data features to clean\n",
    "\n",
    "        annotate_list: list of data features to annotate\n",
    "\n",
    "        pad_length (int): Max sentence length\n",
    "\n",
    "        early_stopping: Dictionary containing patience value (int) and delta value (float). The patience determines the number of epochs to wait to achieve the given delta\n",
    "\n",
    "        batch_size (int): Number of sentences in batch. Default is 32.\n",
    "\n",
    "        epochs (int): Number of times to run through all batches. Default value is 3 according to 2-4 recommended in original BERT paper.\n",
    "\n",
    "        learning_rate (float): Default value is 2e-5 according to recommended value from original BERT paper.\n",
    "\n",
    "        weight decay (float): Default value is 0.1 \n",
    "\n",
    "        warmup (float): Default value is 0.06; percentage of training steps in warmup\n",
    "        \"\"\"\n",
    "    \n",
    "        self.pad_length = pad_length\n",
    "        self.batch_size = batch_size\n",
    "        self.early_stop_vals = early_stop_vals\n",
    "        self.train_labels = torch.Tensor(train_labels.values).to(torch.int64)\n",
    "        self.dev_labels = torch.Tensor(dev_labels.values).to(torch.int64)\n",
    "        self.train_dataloader = self.clean(train_data, normalize_list, annotate_list, self.train_labels)\n",
    "        self.val_dataloader = self.clean(dev_data, normalize_list, annotate_list, self.dev_labels)\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, num_warmup_steps = warmup * (len(self.train_dataloader) * epochs), num_training_steps = (1-warmup) * (len(self.train_dataloader) * epochs))\n",
    "\n",
    "        self.train_loss_values, self.val_loss_values = [], []\n",
    "\n",
    "        for epoch in trange(epochs, desc= \"Epoch\"):\n",
    "            if self.early_stopping() == False:\n",
    "                print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "                print('Training...')\n",
    "\n",
    "                train_total_loss = 0\n",
    "\n",
    "                self.model.train()\n",
    "\n",
    "                for step, batch in enumerate(self.train_dataloader):\n",
    "                    if step % 50 == 0:\n",
    "                        print(\"Processing batch...{}\".format(step))\n",
    "                        print(\"  Batch {:>5,}  of  {:>5,}.\".format(step, len(self.train_dataloader)))\n",
    "\n",
    "                    b_input_ids, b_input_mask, b_labels = tuple(t.to(self.device) for t in batch)\n",
    "\n",
    "                    self.model.zero_grad()  \n",
    "\n",
    "                    outputs = self.model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels.unsqueeze(0))\n",
    "\n",
    "                    train_total_loss += outputs[0].item()\n",
    "                    outputs[0].backward()\n",
    "\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                avg_train_loss = train_total_loss / len(self.train_dataloader)            \n",
    "                self.train_loss_values.append(avg_train_loss)\n",
    "\n",
    "                print()\n",
    "                print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "\n",
    "                print()\n",
    "                print(\"Running Validation...\")\n",
    "                print()\n",
    "\n",
    "                val_total_loss, val_total_len = 0, 0 \n",
    "                num_correct = 0\n",
    "                val_losses = []\n",
    "\n",
    "\n",
    "                self.model.eval()\n",
    "\n",
    "                for batch in self.val_dataloader:\n",
    "                    val_total_len += batch[0].shape[0]\n",
    "                    b_input_ids, b_input_mask, b_labels = tuple(t.to(self.device) for t in batch)\n",
    "\n",
    "                    with torch.no_grad():        \n",
    "\n",
    "                        outputs = self.model(b_input_ids, attention_mask=b_input_mask, labels=b_labels.unsqueeze(0))\n",
    "  \n",
    "                    val_total_loss += outputs[0].item()\n",
    "\n",
    "                    pred = outputs[1].argmax(1, keepdim=True).float()\n",
    "                    correct_tensor = pred.eq(b_labels.float().view_as(pred))\n",
    "                    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "                    num_correct += np.sum(correct)\n",
    "\n",
    "                val_acc = num_correct / val_total_len\n",
    "                avg_val_loss = val_total_loss / len(self.val_dataloader)  \n",
    "                self.val_loss_values.append(avg_val_loss)\n",
    "\n",
    "                print(f\"Epoch | Validation Accuracy | Training Loss | Validation Loss\")\n",
    "                print(f\"{epoch+1:5d} |       {val_acc:.5f}       |    {avg_train_loss:.5f}    |     {avg_val_loss:.5f}\")\n",
    "\n",
    "                print()\n",
    "\n",
    "                if epoch == (epochs-1):\n",
    "                    print(\"Training complete!\")\n",
    "                    return self.training_plot()\n",
    "                else:\n",
    "                    continue\n",
    "      \n",
    "            else:\n",
    "                print(\"Stopping early...\")\n",
    "                print(\"Training complete!\")\n",
    "                return self.training_plot()\n",
    "            \n",
    "    def early_stopping(self):\n",
    "        \"\"\"\n",
    "        Determines whether or not the model will keep running based on the patience and delta given relative to the val loss\n",
    "        \"\"\"\n",
    "        if len(self.val_loss_values) > self.early_stop_vals[\"patience\"]:\n",
    "            if self.val_loss_values[-1] <= np.mean(np.array(self.val_loss_values[-1-self.early_stop_vals[\"patience\"]:-1])) - self.early_stop_vals[\"delta\"]:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def test(self, test_data, test_labels, normalize_list, annotate_list):\n",
    "        \"\"\"\n",
    "        Tests the model's performance based on a several metrics\n",
    "\n",
    "        test_data: Pandas series object containing text data\n",
    "\n",
    "        test_labels: Pandas series object containing labels\n",
    "\n",
    "        normalize_list: list of data features to clean\n",
    "\n",
    "        annotate_list: list of data features to annotate\n",
    "        \"\"\"\n",
    "        self.test_labels = torch.Tensor(test_labels.values).to(torch.int64)\n",
    "        self.test_dataloader = self.clean(test_data, normalize_list, annotate_list, self.test_labels)\n",
    "    \n",
    "        print('Predicting labels for {} sentences...'.format(len(self.test_labels)))\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        predictions, true_labels = [], []\n",
    "\n",
    "        for batch in self.test_dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = tuple(t.to(self.device) for t in batch)\n",
    "      \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(b_input_ids, attention_mask=b_input_mask)\n",
    "\n",
    "            logits = outputs[0].detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            predictions.append(logits)\n",
    "            true_labels.append(label_ids)\n",
    "\n",
    "        print('    DONE.')\n",
    "    \n",
    "        return self.metrics(true_labels, predictions)\n",
    "\n",
    "\n",
    "    def training_plot(self):\n",
    "        \"\"\"\n",
    "        Plots loss after each epoch\n",
    "\n",
    "        training_loss_values: list of floats; output from fine_tune function\n",
    "\n",
    "        val_loss_values: list of floats; output from fine_tune function\n",
    "        \"\"\"\n",
    "        sns.set(style='darkgrid')\n",
    "        plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "        plt.plot(self.train_loss_values, 'b-o', label=\"train\")\n",
    "        plt.plot(self.val_loss_values, 'g-o', label=\"valid\")\n",
    "\n",
    "        #plt.title(\"Training and Validation loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        return plt.show()\n",
    "\n",
    "  \n",
    "    def metrics(self, labels, preds):\n",
    "        \"\"\"\n",
    "        Returns the Matthew's correlation coefficient, accuracy rate, true positive rate, true negative rate, false positive rate, false negative rate, precission, recall, and f1 score\n",
    "\n",
    "        labels: list of correct labels\n",
    "\n",
    "        pred: list of model predictions\n",
    "        \"\"\"\n",
    "\n",
    "        labels = functools.reduce(operator.iconcat, labels, []) #labels and preds lists of lists --> need to flatten \n",
    "        preds = functools.reduce(operator.iconcat, preds, [])\n",
    "\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "\n",
    "        mcc = matthews_corrcoef(labels, pred_flat)\n",
    "        acc = accuracy_score(labels, pred_flat)#np.sum(pred_flat == labels) / len(labels)\n",
    "        cm = confusion_matrix(labels, pred_flat)\n",
    "\n",
    "        f1 = f1_score(labels, pred_flat, average= \"weighted\")\n",
    "        precision = precision_score(labels, pred_flat, average= \"weighted\")\n",
    "        recall = f1_score(labels, pred_flat, average= \"weighted\")\n",
    "\n",
    "        self.results = {\n",
    "            \"mcc\": mcc,\n",
    "            \"acc\": acc,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "\n",
    "        return self.results, labels, pred_flat\n",
    "\n",
    "    def save(self, output_directory, test_name, train_name, predictions_name, labels, pred_flat):\n",
    "        \"\"\"\n",
    "        This function saves the model to a specified directory.\n",
    "        \n",
    "        output_directory: Folder to save file in\n",
    "\n",
    "        test_name: File name for dictionary containing model test performance across metrics\n",
    "\n",
    "        train_name: File name for dictionary containing model train performance across metrics\n",
    "\n",
    "        labels: List of labels for test set\n",
    "\n",
    "        preds_flat: List of model predictions after passed through argmax()\n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    " \n",
    "        output_directory = os.path.join(output_directory, self.model_selection)\n",
    "\n",
    "        output_test_file = os.path.join(output_directory, test_name)\n",
    "        output_train_file = os.path.join(output_directory, train_name)\n",
    "        output_predictions_file = os.path.join(output_directory, predictions_name)\n",
    "\n",
    "        print(output_directory)\n",
    "\n",
    "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model \n",
    "        model_to_save.save_pretrained(output_directory) \n",
    "        self.tokenizer.save_pretrained(output_directory)\n",
    "\n",
    "        training_dict = {\"train_loss\": self.train_loss_values, \"val_loss\": self.val_loss_values}\n",
    "        np.save(output_train_file, training_dict)\n",
    "        np.save(output_test_file, self.results)\n",
    "\n",
    "        test_predictions = pd.DataFrame([labels, pred_flat])\n",
    "        test_predictions = test_predictions.T\n",
    "        test_predictions = test_predictions.rename(columns={0: 'Labels', 1: 'Predictions'})\n",
    "        test_predictions.to_csv(output_predictions_file)\n",
    "\n",
    "        return print(\"Saving complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RoBERTa fine-tuning hyperparameters for GLUE: \n",
    "NORMALIZE_LIST = [\"url\", \"hashtag\", \"user\"]\n",
    "ANNOTATE_LIST = []\n",
    "LEARNING_RATE = [1e-5, 2e-5, 3e-5]\n",
    "N_EPOCHS = 10 \n",
    "EARLY_STOPPING = {\"patience\": 2, \"delta\": 0.03}\n",
    "N_LABELS =  4\n",
    "PAD_LENGTH = 64\n",
    "BATCH_SIZE = [16, 32]\n",
    "WEIGHT_DECAY = 0.1 \n",
    "WARMUP = 0.06 \n",
    "OUTPUT_DIR = \"\" #create seperate folders for each model before\n",
    "TEST_NAME = \"dogwhistle_test_results.npy\"\n",
    "TRAIN_NAME = \"dogwhistlee_train_results.npy\"\n",
    "PREDICTIONS_NAME = \"dogwhistle_test_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "max_f1_value = 0\n",
    "\n",
    "for i in BATCH_SIZE:\n",
    "    learning_rate_dict = {}\n",
    "    for j in LEARNING_RATE: \n",
    "        Classifier = TransformerClassifier(\"RoBERTa\", N_LABELS) \n",
    "        Classifier.fine_tune(train[\"text.clean\"], train[\"labels\"], dev[\"text.clean\"], dev[\"labels\"], NORMALIZE_LIST, ANNOTATE_LIST, PAD_LENGTH, EARLY_STOPPING, i, N_EPOCHS, j, WEIGHT_DECAY, WARMUP) \n",
    "        learning_rate_dict[j], labels, preds_flat = Classifier.test(test[\"text.clean\"], test[\"labels\"], NORMALIZE_LIST, ANNOTATE_LIST)\n",
    "\n",
    "    if learning_rate_dict[j][\"f1\"] >= max_f1_value: #only save best model\n",
    "        max_f1_value = learning_rate_dict[j][\"f1\"]\n",
    "        Classifier.save(OUTPUT_DIR, TEST_NAME, TRAIN_NAME, PREDICTIONS_NAME, labels, preds_flat)\n",
    "\n",
    "    results_dict[i] = learning_rate_dict \n",
    "\n",
    "#save complete training results\n",
    "np.save(os.path.join(os.path.join(OUTPUT_DIR, \"RoBERTa\"), \"dogwhistle_total_training_results.npy\"), results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
