{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelperFunctions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17xe7JRRTnfyqGlazHlgprYzlmuasiKoe",
      "authorship_tag": "ABX9TyMppEwoipIuGYHuREtWsHIB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TPdAN-QaQXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ekphrasis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pPMlKNtaQkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRWhJJDHY2Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratify(data, strata_field: str, split_sizes, **kwargs):\n",
        "    \"\"\"Stratify and split the data.\n",
        "    :data (base.DataType): dataset to split.\n",
        "    :split_sizes (int | base.List[int]): The number of documents in each split.\n",
        "    :strata_field (str): Name of label field.\n",
        "    :returns train, dev, test (base.Tuple[list, base.Union[list, None], list]): Return stratified splits.\n",
        "    \"\"\"\n",
        "\n",
        "    train_size = split_sizes[0]\n",
        "\n",
        "    num_splits = len(split_sizes)\n",
        "    if num_splits == 1:\n",
        "        test_size = 1 - split_sizes[0]\n",
        "    elif num_splits == 2:\n",
        "        test_size = split_sizes[-1]\n",
        "    elif num_splits == 3:\n",
        "        dev_size = split_sizes[1]\n",
        "        test_size = split_sizes[2]\n",
        "\n",
        "    stratified_train_list = []\n",
        "    stratified_dev_list = []\n",
        "    stratified_test_list = []\n",
        "\n",
        "    for i in set(data[strata_field]):\n",
        "      temp_df = data[data[strata_field] == i]\n",
        "\n",
        "      if dev_size is not None:\n",
        "        train, temp_test = train_test_split(temp_df, test_size=test_size+dev_size, random_state=42)\n",
        "        dev, test = train_test_split(temp_test, test_size= (test_size/(test_size+dev_size)), random_state=42)\n",
        "\n",
        "        stratified_train_list.append(train)\n",
        "        stratified_dev_list.append(dev)\n",
        "        stratified_test_list.append(test)\n",
        "\n",
        "      else:\n",
        "        train, test = train_test_split()\n",
        "        stratified_train_list.append(train)\n",
        "        stratified_test_list.append(test)\n",
        "\n",
        "\n",
        "    train = pd.concat(stratified_train_list)\n",
        "    dev = pd.concat(stratified_dev_list)\n",
        "    test = pd.concat(stratified_test_list)\n",
        "\n",
        "    train = shuffle(train).reset_index(drop=True)\n",
        "    dev = shuffle(dev).reset_index(drop=True)\n",
        "    test = shuffle(test).reset_index(drop=True)\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "# df = pd.read_csv(\"\", encoding='utf-8')\n",
        "# train, dev, test = stratify(df, \"\", [0.8, 0.1, 0.1])\n",
        "\n",
        "\n",
        "def clean_text(data, normalize_list, annotate_list):\n",
        "        \"\"\"\n",
        "        This function preprocesses the text using the Ekphrasis library\n",
        "        \n",
        "        data: Pandas series object containing strings of text\n",
        "\n",
        "        normalize_list: list of data features to clean\n",
        "\n",
        "        annotate_list: list of data features to annotate\n",
        "        \"\"\"\n",
        "\n",
        "        text_processor = TextPreProcessor(\n",
        "            normalize= normalize_list,\n",
        "            annotate= annotate_list,\n",
        "            fix_html=True,\n",
        "            segmenter=\"twitter\", \n",
        "            unpack_hashtags=True,  \n",
        "            unpack_contractions=True,  \n",
        "            spell_correct_elong=True,  \n",
        "            tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "            dicts=[emoticons]\n",
        "        )\n",
        "\n",
        "        clean_data = data.map(lambda x: \" \".join(text_processor.pre_process_doc(x)))\n",
        "\n",
        "        return clean_data\n",
        "\n",
        "\n",
        "def early_stopping(val_loss_values, early_stop_vals):\n",
        "    \"\"\"\n",
        "    Determines whether or not the model will keep running based on the patience and delta given relative to the val loss\n",
        "    \"\"\"\n",
        "    if len(val_loss_values) > early_stop_vals[\"patience\"]:\n",
        "      if val_loss_values[-1] <= np.mean(np.array(val_loss_values[-1-self.early_stop_vals[\"patience\"]:-1])) - early_stop_vals[\"delta\"]:\n",
        "        return False\n",
        "      else:\n",
        "        return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "\n",
        "def training_plot(train_loss_values, val_loss_values):\n",
        "    \"\"\"\n",
        "    Plots loss after each epoch\n",
        "\n",
        "    training_loss_values: list of floats; output from fine_tune function\n",
        "\n",
        "    val_loss_values: list of floats; output from fine_tune function\n",
        "    \"\"\"\n",
        "    sns.set(style='darkgrid')\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    plt.plot(train_loss_values, 'b-o', label=\"train\")\n",
        "    plt.plot(val_loss_values, 'g-o', label=\"valid\")\n",
        "\n",
        "    #plt.title(\"Training and Validation loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    #fig.savefig(\"dogwhistle_train_plot.png\",bbox_inches='tight')\n",
        "\n",
        "    return plt.show()\n",
        "\n",
        "\n",
        "def metrics(labels, preds, argmax_needed: bool = False):\n",
        "    \"\"\"\n",
        "    Returns the Matthew's correlation coefficient, accuracy rate, true positive rate, true negative rate, false positive rate, false negative rate, precission, recall, and f1 score\n",
        "    \n",
        "    labels: list of correct labels\n",
        "\n",
        "    pred: list of model predictions\n",
        "    \"\"\"\n",
        "    labels = labels\n",
        "    preds = preds\n",
        "\n",
        "    if argmax_needed == True:\n",
        "        preds = np.argmax(preds, axis=1).flatten()\n",
        "\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "\n",
        "    f1 = f1_score(labels, preds, average= \"weighted\")\n",
        "    precision = precision_score(labels, preds, average= \"weighted\")\n",
        "    recall = f1_score(labels, preds, average= \"weighted\")\n",
        "\n",
        "    results = {\n",
        "        \"mcc\": mcc,\n",
        "        \"acc\": acc,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "    \n",
        "    return results, labels, preds\n",
        "\n",
        "\n",
        "def model_saver(model, model_type, output_directory, training_dict, labels, preds, results, tokenizer= None):\n",
        "    \"\"\"\n",
        "    model: Model to be saved\n",
        "    \n",
        "    model_type (string): Name of model\n",
        "    \n",
        "    output_directory: Directory to folder to save file in\n",
        "\n",
        "    training_dict: Dictionary of training and validation values \n",
        "\n",
        "    labels: List of labels for test set\n",
        "\n",
        "    preds: List of model predictions after passed through argmax()\n",
        "\n",
        "    results: Dictionary of metrics\n",
        "\n",
        "    tokenizer: Tokenizer to be saved. Defaulted to None.\n",
        "    \"\"\"\n",
        "\n",
        "    output_directory = os.path.join(output_directory, model_type)\n",
        "    \n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    np.save(model_type+\"_dogwhistle_train_results.npy\", training_dict) #save training dict\n",
        "    np.save(model_type+\"_dogwhistle_test_results.npy\", results) #save test metrics\n",
        "    \n",
        "    test_predictions = pd.DataFrame([labels, preds]) #save predictions and labels \n",
        "    test_predictions = test_predictions.T\n",
        "    test_predictions = test_predictions.rename(columns={0: 'Labels', 1: 'Predictions'})\n",
        "    test_predictions.to_csv(model_type+\"_dogwhistle_predictions.csv\")\n",
        "\n",
        "    #save models\n",
        "    if model_type in [\"LSTM\", \"resnet\", \"alexnet\", \"vgg\", \"squeezenet\", \"densenet\", \"inception\"]:\n",
        "        torch.save(model.state_dict(), file_name+\"_model\")\n",
        "\n",
        "    if model_type in [\"AlBERT\", \"BART\", \"BERT\", \"DistilBERT\", \"RoBERTa\", \"XLNet\"]:\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model \n",
        "        model_to_save.save_pretrained(output_directory) \n",
        "        tokenizer.save_pretrained(output_directory)\n",
        "\n",
        "    return print(\"Saving complete.\")\n",
        "\n",
        "\n",
        "def confusion_matrix_plotter(results, save_name, x_tick_labels, y_tick_labels, color):\n",
        "    \"\"\"\n",
        "    results: dictionary item containing key of confusion matrix (output of sklearn confusion_matrix())\n",
        "\n",
        "    x_tick_labels: list of tick labels on x axis\n",
        "\n",
        "    y_tick_labels: list of tick labels on y axis\n",
        "\n",
        "    save_name: name of image to be produced with .png\n",
        "\n",
        "    color: color selection from matplotlib cmap choices: https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n",
        "    \"\"\"\n",
        "\n",
        "    df_cm = pd.DataFrame(results.ravel()[0][\"confusion_matrix\"])\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 12))\n",
        "    \n",
        "    plt.rc('axes', labelsize=14)  \n",
        "    plt.rc('xtick', labelsize=12)   \n",
        "    plt.rc('ytick', labelsize=12)       \n",
        "\n",
        "    #plt.subplot(2, 2, 1)\n",
        "    g1 = sns.heatmap(df_cm, annot=True, fmt='g', cmap=color)\n",
        "    g1.set_xlabel('Predicted Label')\n",
        "    g1.set_ylabel('True Label', rotation=0) \n",
        "    g1.xaxis.set_ticklabels(x_tick_labels, rotation=0) \n",
        "    g1.yaxis.set_ticklabels(y_tick_labels, rotation=0) \n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return fig.savefig(save_name,bbox_inches='tight')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}