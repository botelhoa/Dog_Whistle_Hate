{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Models_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1k7KsHBNTQTn3Ab_-oCnygik2Ll_YLcb7",
      "authorship_tag": "ABX9TyODYLj0BuaWv5IHriPyK/wA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDAdj3hAvtSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "700cb747-ef38-4f45-888f-afc123d0d3f0"
      },
      "source": [
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import os \n",
        "\n",
        "from PIL import Image\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.applications import InceptionV3, VGG16, DenseNet201, MobileNetV2, ResNet152V2, InceptionResNetV2, NASNetLarge, Xception\n",
        "from matplotlib import pyplot\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix, precision_score, recall_score, f1_score, accuracy_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSvNrWhEL_Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Move train data to colab virtual machine to increase speed\n",
        "!cp -r \"/content/drive/My Drive/Dog_Whistle_Code/Data/Train/Train_images\" \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc52jxtAL_nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Move dev data to colab virtual machine to increase speed\n",
        "!cp -r \"/content/drive/My Drive/Dog_Whistle_Code/Data/Validation/Validation_images\" \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYGVNCfjL_6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Move test data to colab virtual machine to increase speed\n",
        "!cp -r \"/content/drive/My Drive/Dog_Whistle_Code/Data/Test/Test_images\" \"/content\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ_-UfG7MUHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics(labels, preds, argmax_needed: bool = False):\n",
        "    \"\"\"\n",
        "    Returns the Matthew's correlation coefficient, accuracy rate, true positive rate, true negative rate, false positive rate, false negative rate, precission, recall, and f1 score\n",
        "    \n",
        "    labels: list of correct labels\n",
        "\n",
        "    pred: list of model predictions\n",
        "    \"\"\"\n",
        "\n",
        "    if argmax_needed == True:\n",
        "        preds = np.argmax(preds, axis=1).flatten()\n",
        "\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "\n",
        "    f1 = f1_score(labels, preds, average= \"weighted\")\n",
        "    precision = precision_score(labels, preds, average= \"weighted\")\n",
        "    recall = recall_score(labels, preds, average= \"weighted\")\n",
        "\n",
        "    results = {\n",
        "        \"mcc\": mcc,\n",
        "        \"acc\": acc,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "    \n",
        "    return results, labels, preds\n",
        "\n",
        "def image_model_saver(image_model, model_type, output_directory, training_dict, labels1, labels2, preds, results1, results2):\n",
        "    \"\"\"\n",
        "    Saves Keras image model and other outputs\n",
        "\n",
        "    image_model: Image model to be saved\n",
        "    \n",
        "    model_type (string): Name of model\n",
        "    \n",
        "    output_directory: Directory to folder to save file in\n",
        "\n",
        "    training_dict: Dictionary of training and validation values \n",
        "\n",
        "    labels1: List of multimodal labels for test set\n",
        "\n",
        "    labels2: List of unimodal labels for test set\n",
        "\n",
        "    preds: List of model predictions after passed through argmax()\n",
        "\n",
        "    results1: Dictionary of metrics on multimodal labels\n",
        "\n",
        "    results2: Dictionary of metrics on uniimodal labels\n",
        "\n",
        "    tokenizer: Tokenizer to be saved. Defaulted to None.\n",
        "    \"\"\"\n",
        "    output_directory = os.path.join(output_directory, model_type)\n",
        "    \n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    os.chdir(output_directory)\n",
        "\n",
        "    np.save(model_type+\"_dogwhistle_train_results.npy\", training_dict) #save training dict\n",
        "    np.save(model_type+\"_dogwhistle_test_results_multimodal.npy\", results1) #save test metrics\n",
        "    np.save(model_type+\"_dogwhistle_test_results_unimodal.npy\", results2) #save test metrics\n",
        "    \n",
        "    test_predictions = pd.DataFrame([labels1, labels2, preds]) #save predictions and labels\n",
        "    test_predictions = test_predictions.T\n",
        "    test_predictions = test_predictions.rename(columns={0: 'Multimodal Labels', 1: 'Unimodal Labels', 2: 'Predictions'})\n",
        "    test_predictions.to_csv(model_type+\"_dogwhistle_predictions.csv\")\n",
        "\n",
        "    image_model.save(\"image_model.h5\") #save model\n",
        "\n",
        "    return print(\"Saving complete.\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uag6jdl-vz1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fine_tune(base_model, train_directory, dev_directory, optimzer, scheduler, image_size: int, num_epochs: int=10, min_delta= 0, patience: int=10, batch_size: int=64, dropout: float=0.5):\n",
        "    \"\"\"\n",
        "    Function for fine tuning pretrained CovNets\n",
        "\n",
        "    base_model: Type of pre-trained model\n",
        "\n",
        "    train_directory: Path to parent folder containing train images sub-divided into folders by label names\n",
        "\n",
        "    dev_directory: Path to parent folder containing dev images sub-divided into folders by label names\n",
        "\n",
        "    optimizer: Algorithim according to which values from the loss function should be back propogated\n",
        "\n",
        "    scheduler: Callback determining learning rate decay\n",
        "\n",
        "    image_size (int): Number of pixels in input dimensions (assumes square shape) \n",
        "\n",
        "    num_epochs (int): Number of passes through train data. Defaulted to 10.\n",
        "\n",
        "    min_delta: Minimum reduction in val loss for early stopping\n",
        "\n",
        "    patience (int): Number of epochs at min_delta before early stopping. Defaulted to 10.\n",
        "\n",
        "    batch_size (int): Size of mini batches used in training. Defaulted to 64.\n",
        "\n",
        "    dropout (int): Percentage of nodes turned off in final softmax layer. Defaulted to 0.5.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #Load data\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(train_directory,\n",
        "                                                        target_size=(image_size, image_size),\n",
        "                                                        classes=[\"None\", \"Hateful\", \"Counter-speech\", \"Reclaimed\"],\n",
        "                                                        class_mode=\"categorical\",\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        shuffle=True,\n",
        "                                                        seed=22)\n",
        "\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(dev_directory,\n",
        "                                                                  target_size=(image_size, image_size),\n",
        "                                                                  classes=[\"None\", \"Hateful\", \"Counter-speech\", \"Reclaimed\"],\n",
        "                                                                  class_mode=\"categorical\",\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  shuffle=True,\n",
        "                                                                  seed=22)\n",
        "                                                                \n",
        "    #Add Classifier atop pre-trained model\n",
        "\n",
        "    # global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # fully-connected layer\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    # logistic layer\n",
        "    predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Train top 5% of pre-trained model layers with top layers\n",
        "    for layer in model.layers[:int(len(model.layers) * 0.95)]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    for layer in model.layers[int(len(model.layers) * 0.95):]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', min_delta=min_delta, patience=patience, verbose=1, mode='auto')\n",
        "    model.compile(optimizer=optimzer, loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "    history = model.fit(train_generator, epochs=num_epochs, validation_data=validation_generator, callbacks=[early_stop, scheduler])\n",
        "    \n",
        "    train_dict = {\"Train Accuracy\": history.history['accuracy'], \"Train Loss\": history.history['loss'], \"Val Accuracy\": history.history['val_accuracy'], \"Val Loss\": history.history['val_loss'] }\n",
        "    \n",
        "    return model, train_dict\n",
        "\n",
        "\n",
        "def test(trained_model, test_directory, image_size: int, batch_size: int=64):\n",
        "    \"\"\"\n",
        "    Outputs metrics, predictions, and labels from image model\n",
        "\n",
        "    trained_model: Trained image model\n",
        "\n",
        "    test_directory: Path to parent folder containing test images sub-divided into folders by label names\n",
        "\n",
        "    image_size (int): Number of pixels in input dimensions (assumes square shape)\n",
        "\n",
        "    batch_size (int): Size of mini batches used in training. Defaulted to 64.\n",
        "    \"\"\"\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(test_directory,\n",
        "                                                      target_size=(image_size, image_size),\n",
        "                                                      classes=[\"None\", \"Hateful\", \"Counter-speech\", \"Reclaimed\"],\n",
        "                                                      class_mode=\"categorical\",\n",
        "                                                      batch_size=batch_size,\n",
        "                                                      shuffle=False,\n",
        "                                                      seed=22)\n",
        "\n",
        "    label_list = []\n",
        "\n",
        "    for i in range(len(test_generator)):\n",
        "        values = np.argmax(test_generator[i][1], axis=1).flatten()\n",
        "        label_list.extend(values)\n",
        "    \n",
        "    preds = trained_model.predict(test_generator)\n",
        "\n",
        "    results, labels, predictions = metrics(label_list, preds, argmax_needed=True)\n",
        "\n",
        "    return results, labels, predictions, test_generator"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BcI9lHIYfwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "InceptionResNet-V2 paper specifies...\n",
        "optimizer = RMSProp\n",
        "epsilon = 1.0\n",
        "learning_rate =  0.045\n",
        "exponential decay every 2 epochs at rate of 0.94\n",
        "image size = (299, 299)\n",
        "\n",
        "NASNet paper specifies... \n",
        "optimizer = RMSProp\n",
        "epsilon = 1.0\n",
        "learning_rate =  0.045\n",
        "drop_out = 0.5\n",
        "epochs = 20\n",
        "exponential decay every 2 epochs at rate of 0.9999\n",
        "image size = (331, 331)\n",
        "\n",
        "Xception paper specifies... \n",
        "optimizer = SGD\n",
        "learning_rate =  0.045\n",
        "drop_out = 0.5\n",
        "exponential decay every 2 epochs at rate of 0.94\n",
        "Momentum: 0.9\n",
        "image size = (299, 299)\n",
        "\"\"\"\n",
        "\n",
        "#Define shared hyperparameters\n",
        "MIN_DELTA = 0.001\n",
        "PATIENCE = 3\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 0.045\n",
        "DROPOUT = 0.5\n",
        "EPSILON = 1.0 \n",
        "TRAIN_LEN = 3998\n",
        "\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/Dog_Whistle_Code/Fine_Tuned_Models/Image\"\n",
        "TRAIN_PATH = \"/content/Train_images\"\n",
        "DEV_PATH = \"/content/Validation_images\"\n",
        "TEST_PATH_UNIMODAL = \"/content/Test_images/Unimodal Labels\"\n",
        "TEST_PATH_MULTIMODAL = \"/content/Test_images/Multimodal Labels\"\n",
        "\n",
        "\n",
        "#InceptionResNet-V2 Hyperparameters\n",
        "IRN_IMAGE_SIZE = 299\n",
        "IRN_OPTIMIZER = RMSprop(learning_rate = LEARNING_RATE, epsilon=EPSILON)\n",
        "\n",
        "def IRN_decay(epoch, lr):\n",
        "    epochs_drop = 2.0\n",
        "    IRN_DECAY_RATE = 0.94\n",
        "    lrate = lr * (IRN_DECAY_RATE**((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "IRN_SCHEDULER = LearningRateScheduler(IRN_decay)\n",
        "\n",
        "\n",
        "#NASNet Hyperparameters\n",
        "NN_IMAGE_SIZE = 331\n",
        "NN_OPTIMIZER = RMSprop(learning_rate= LEARNING_RATE, epsilon=EPSILON)\n",
        "\n",
        "def NN_decay(epoch, lr):\n",
        "    epochs_drop = 2.0\n",
        "    NN_DECAY_RATE = 0.9999\n",
        "    lrate = lr * (NN_DECAY_RATE**((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "NN_SCHEDULER = LearningRateScheduler(NN_decay)\n",
        "\n",
        "\n",
        "#Xception Hyperparametes\n",
        "X_IMAGE_SIZE = 299\n",
        "X_OPTIMIZER = SGD(lr= LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "def X_decay(epoch, lr):\n",
        "    epochs_drop = 2.0\n",
        "    X_DECAY_RATE = 0.94\n",
        "    lrate = lr * (X_DECAY_RATE**((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "X_SCHEDULER = LearningRateScheduler(X_decay)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aY1XnSktCTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "7c6f5fc7-ef69-4c8a-d709-0ac2a76b9c95"
      },
      "source": [
        "#Visualize learning rate decay\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# vals = []\n",
        "# lr = 0.045\n",
        "# for i in range(20):\n",
        "#     val = step_decay(i, lr)\n",
        "#     vals.append(val)\n",
        "#     lr = val\n",
        "\n",
        "# plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# plt.plot(vals)\n",
        "\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"Learning Rates\")\n",
        "# plt.xticks(np.arange(20))\n",
        "# plt.legend()\n",
        "\n",
        "# #plt.savefig(\"learning_rate_decay.png\",bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5f7fc90cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id7SmAIu9pDt",
        "colab_type": "text"
      },
      "source": [
        "### Run Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr93IHXAfpBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "e5566d7d-26ce-4ef4-f873-4de95dbf76ee"
      },
      "source": [
        "#Train and Test InceptionResNet-V2\n",
        "model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(IRN_IMAGE_SIZE, IRN_IMAGE_SIZE, 3))\n",
        "trained_model, train_dict = fine_tune(model, TRAIN_PATH, DEV_PATH, IRN_OPTIMIZER, IRN_SCHEDULER, IRN_IMAGE_SIZE, NUM_EPOCHS, MIN_DELTA, PATIENCE, BATCH_SIZE, DROPOUT)   \n",
        "results1, labels1, predictions1, datagenerator1 = test(trained_model, TEST_PATH_MULTIMODAL, IRN_IMAGE_SIZE, BATCH_SIZE) \n",
        "results2, labels2, predictions2, datagenerator2 = test(trained_model, TEST_PATH_UNIMODAL, IRN_IMAGE_SIZE, BATCH_SIZE)\n",
        "print(results1)\n",
        "print(results2)\n",
        "image_model_saver(trained_model, \"InceptionResNetV2\", OUTPUT_DIR, train_dict, labels1, labels2, predictions1, results1, results2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 502 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 502 images belonging to 4 classes.\n",
            "{'mcc': 0.14853090316382364, 'acc': 0.5338645418326693, 'confusion_matrix': array([[164,  97,   0,   7],\n",
            "       [ 81, 102,   0,   2],\n",
            "       [  8,   4,   0,   0],\n",
            "       [ 24,  11,   0,   2]]), 'precision': 0.5051321174604282, 'recall': 0.5158596466494282, 'f1': 0.5158596466494282}\n",
            "Saving complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Nh8_J7fuJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "88bc12d2-359b-4a8f-8455-723b016a2a03"
      },
      "source": [
        "#Train and Test NASNet\n",
        "model = NASNetLarge(weights='imagenet', include_top=False, input_shape=(NN_IMAGE_SIZE, NN_IMAGE_SIZE, 3))\n",
        "trained_model, train_dict = fine_tune(model, TRAIN_PATH, DEV_PATH, NN_OPTIMIZER, NN_SCHEDULER, NN_IMAGE_SIZE, NUM_EPOCHS, MIN_DELTA, PATIENCE, BATCH_SIZE, DROPOUT)   \n",
        "results1, labels1, predictions1, datagenerator1 = test(trained_model, TEST_PATH_MULTIMODAL, NN_IMAGE_SIZE, BATCH_SIZE) \n",
        "results2, labels2, predictions2, datagenerator2 = test(trained_model, TEST_PATH_UNIMODAL, NN_IMAGE_SIZE, BATCH_SIZE) \n",
        "print(results1)\n",
        "print(results2)\n",
        "image_model_saver(trained_model, \"NASNet\", OUTPUT_DIR, train_dict, labels1, labels2, predictions1, results1, results2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large-no-top.h5\n",
            "343613440/343610240 [==============================] - 4s 0us/step\n",
            "Found 3998 images belonging to 4 classes.\n",
            "Found 500 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "125/125 [==============================] - 447s 4s/step - loss: 0.7677 - accuracy: 0.7066 - val_loss: 1.0924 - val_accuracy: 0.7360\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 401s 3s/step - loss: 0.6820 - accuracy: 0.7376 - val_loss: 0.4869 - val_accuracy: 0.7160\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 401s 3s/step - loss: 0.6406 - accuracy: 0.7536 - val_loss: 0.7857 - val_accuracy: 0.6660\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 401s 3s/step - loss: 0.6092 - accuracy: 0.7664 - val_loss: 0.7318 - val_accuracy: 0.7300\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 401s 3s/step - loss: 0.5732 - accuracy: 0.7691 - val_loss: 0.6357 - val_accuracy: 0.7340\n",
            "Epoch 00005: early stopping\n",
            "Found 502 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 502 images belonging to 4 classes.\n",
            "{'mcc': 0.20156034014285756, 'acc': 0.5856573705179283, 'confusion_matrix': array([[232,  34,   0,   2],\n",
            "       [124,  61,   0,   0],\n",
            "       [ 11,   1,   0,   0],\n",
            "       [ 33,   3,   0,   1]]), 'precision': 0.5612813392893075, 'recall': 0.5328237442403785, 'f1': 0.5328237442403785}\n",
            "Saving complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qGBLi2tfuhW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "5254f70c-f9aa-4f51-cc45-7e803d67ca13"
      },
      "source": [
        "#Train and Test Xception\n",
        "model = Xception(weights='imagenet', include_top=False, input_shape=(X_IMAGE_SIZE, X_IMAGE_SIZE, 3))\n",
        "trained_model, train_dict = fine_tune(model, TRAIN_PATH, DEV_PATH, X_OPTIMIZER, X_SCHEDULER, X_IMAGE_SIZE, NUM_EPOCHS, MIN_DELTA, PATIENCE, BATCH_SIZE, DROPOUT)   \n",
        "results1, labels1, predictions1, datagenerator1 = test(trained_model, TEST_PATH_MULTIMODAL, X_IMAGE_SIZE, BATCH_SIZE) \n",
        "results2, labels2, predictions2, datagenerator2 = test(trained_model, TEST_PATH_UNIMODAL, X_IMAGE_SIZE, BATCH_SIZE)\n",
        "print(results1)\n",
        "print(results2)\n",
        "image_model_saver(trained_model, \"Xception\", OUTPUT_DIR, train_dict, labels1, labels2, predictions1, results1, results2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Found 3998 images belonging to 4 classes.\n",
            "Found 500 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "125/125 [==============================] - 165s 1s/step - loss: 0.8139 - accuracy: 0.7051 - val_loss: 1.4008 - val_accuracy: 0.7600\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 148s 1s/step - loss: 0.7101 - accuracy: 0.7296 - val_loss: 0.6622 - val_accuracy: 0.7220\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 149s 1s/step - loss: 0.6823 - accuracy: 0.7424 - val_loss: 0.9263 - val_accuracy: 0.7080\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 150s 1s/step - loss: 0.6385 - accuracy: 0.7556 - val_loss: 0.7307 - val_accuracy: 0.7100\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 149s 1s/step - loss: 0.5989 - accuracy: 0.7696 - val_loss: 0.7218 - val_accuracy: 0.7460\n",
            "Epoch 00005: early stopping\n",
            "Found 502 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 502 images belonging to 4 classes.\n",
            "{'mcc': 0.24124970097295248, 'acc': 0.603585657370518, 'confusion_matrix': array([[241,  27,   0,   0],\n",
            "       [123,  62,   0,   0],\n",
            "       [ 10,   2,   0,   0],\n",
            "       [ 35,   2,   0,   0]]), 'precision': 0.5602593700178908, 'recall': 0.5444710854042994, 'f1': 0.5444710854042994}\n",
            "{'mcc': 0.2893186546822142, 'acc': 0.7171314741035857, 'confusion_matrix': array([[309,  39,   0,   0],\n",
            "       [ 70,  51,   0,   0],\n",
            "       [  9,   1,   0,   0],\n",
            "       [ 21,   2,   0,   0]]), 'precision': 0.655914868799901, 'recall': 0.6808232938196227, 'f1': 0.6808232938196227}\n",
            "Saving complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGulcPEZAi0L",
        "colab_type": "text"
      },
      "source": [
        "### Exract Image Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLuHmkmpyrFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0b5a558b-b132-4a42-f277-8a5a8daf722e"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "#Train and Test Xception\n",
        "ImageExtractor = load_model('/content/drive/My Drive/Dog_Whistle_Code/Fine_Tuned_Models/Image/Xception/image_model.h5') #using pre-trained Xception\n",
        "\n",
        "results1, labels1, predictions1, test_generator1 = test(ImageExtractor, TEST_PATH_MULTIMODAL, X_IMAGE_SIZE, BATCH_SIZE) \n",
        "results2, labels2, predictions2, test_generator2 = test(ImageExtractor, TEST_PATH_UNIMODAL, X_IMAGE_SIZE, BATCH_SIZE)"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 502 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 502 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVN8ie366rlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def id_extractor(test_generator):\n",
        "    \"\"\"\n",
        "    test_generator: Generator object from Keras flow_from_directory()\n",
        "    \"\"\"\n",
        "\n",
        "    ids = []\n",
        "\n",
        "    for i in test_generator.filenames:\n",
        "        id_label = i.split(\"/\")[1]\n",
        "        id_label = id_label.split(\".\")[0]\n",
        "        ids.append(int(id_label))\n",
        "\n",
        "    return ids\n",
        "\n",
        "# Get label lists\n",
        "ids1 = id_extractor(test_generator1)\n",
        "ids2 = id_extractor(test_generator2)"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHDPMBY2zy5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create multimodal DF\n",
        "test_predictions1 = pd.DataFrame([ids1, labels1, predictions1]) \n",
        "test_predictions1 = test_predictions1.T\n",
        "test_predictions1 = test_predictions1.rename(columns={0: 'image_number', 1: 'Multimodal Labels', 2: 'Predictions_multimodal'})\n",
        "\n",
        "# Create unimodal DF\n",
        "test_predictions2 = pd.DataFrame([ids2, labels2, predictions2]) \n",
        "test_predictions2 = test_predictions2.T\n",
        "test_predictions2 = test_predictions2.rename(columns={0: 'image_number', 1: 'Unimodal Labels', 2: 'Predictions_unimodal'})\n",
        "\n",
        "# Merge and Save DFs\n",
        "test_predictions = test_predictions1.merge(test_predictions2, on = \"image_number\")\n",
        "test_predictions.to_csv(\"/content/drive/My Drive/Dog_Whistle_Code/Fine_Tuned_Models/Image/Xception/Xception_dogwhistle_predictions.csv\")"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYCuxuuyFvzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2837e99-4304-49d7-b361-f5e8d1e16afc"
      },
      "source": [
        "# Check that values are the same\n",
        "print(f1_score(test_predictions[\"Multimodal Labels\"].values.tolist(), test_predictions[\"Predictions_multimodal\"].values.tolist(), average = 'weighted'))\n",
        "print(f1_score(test_predictions[\"Unimodal Labels\"].values.tolist(), test_predictions[\"Predictions_unimodal\"].values.tolist(), average = 'weighted'))"
      ],
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5444710854042994\n",
            "0.6808232938196227\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}